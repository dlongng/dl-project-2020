{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Resnet50_8_12.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E3q4y7NkZTkC","executionInfo":{"status":"ok","timestamp":1607483181401,"user_tz":-420,"elapsed":17747,"user":{"displayName":"Định Mai Thị","photoUrl":"","userId":"04642252131677430012"}},"outputId":"77f094f9-475f-4b19-db7b-4b2676d77037"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3tjlBVOKKW-w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607483186202,"user_tz":-420,"elapsed":8599,"user":{"displayName":"Định Mai Thị","photoUrl":"","userId":"04642252131677430012"}},"outputId":"a773fe34-19af-44cd-870b-a3b4fae41c0e"},"source":["!pip install tfa-nightly"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tfa-nightly\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/b1/ec24cfa2c93df1e52fa235ce6d154cce1013f27ce69f7a6be1b3ed8a54fe/tfa_nightly-0.12.0.dev20201208041358-cp36-cp36m-manylinux2010_x86_64.whl (743kB)\n","\r\u001b[K     |▍                               | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 25.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 12.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 10.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 5.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 6.4MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 6.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 143kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 153kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 174kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 184kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 194kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 204kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 215kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 225kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 235kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 245kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 266kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 276kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 286kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 296kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 307kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 317kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 337kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 348kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 358kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 368kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 378kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 389kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 399kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 409kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 430kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 440kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 450kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 460kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 471kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 481kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 491kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 501kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 512kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 522kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 532kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 542kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 552kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 563kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 573kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 583kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 593kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 604kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 614kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 624kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 634kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 645kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 655kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 665kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 675kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 686kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 696kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 706kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 716kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 727kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 737kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 747kB 6.9MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tfa-nightly) (2.7.1)\n","Installing collected packages: tfa-nightly\n","Successfully installed tfa-nightly-0.12.0.dev20201208041358\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZFD2hDn1zbq","executionInfo":{"status":"ok","timestamp":1607483188598,"user_tz":-420,"elapsed":10424,"user":{"displayName":"Định Mai Thị","photoUrl":"","userId":"04642252131677430012"}},"outputId":"66b5a3d3-d1de-4de4-d8cf-d6b0e0035a2a"},"source":["!pip install tensorflow-addons"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (0.8.3)\n","Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (2.7.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EQ8zehLcjjGF"},"source":["# Import Library\n","import tensorflow.keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\n","from tensorflow.keras.layers import Conv2D,MaxPooling2D\n","import tensorflow_addons as tfa\n","from tensorflow.keras.optimizers import RMSprop,SGD,Adam,Adadelta\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","import matplotlib.pyplot as plt\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TaKQDO9xlF4K"},"source":["# Variable Definition\n","num_classes=7\n","height,width=48,48\n","batch_size=128"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pRolT_S0lOdI"},"source":["!rm -rf fer2013\n","!mkdir fer2013\n","!mkdir fer2013/train\n","!mkdir fer2013/valid\n","!mkdir fer2013/test\n","! unzip -q '/content/drive/MyDrive/fer2013/train.zip' -d fer2013/train\n","! unzip -q '/content/drive/MyDrive/fer2013/test-public.zip' -d fer2013/valid\n","! unzip -q '/content/drive/MyDrive/fer2013/test-private.zip' -d fer2013/test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tKKhJq6tlIQ-"},"source":["# Dataset Directory\n","train_dir='fer2013/train'\n","validation_dir='fer2013/valid'\n","test_dir = 'fer2013/test'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pYPn6YMpRSzG"},"source":["def smooth_labels(y, smooth_factor):\n","    '''Convert a matrix of one-hot row-vector labels into smoothed versions.\n","    https://www.dlology.com/blog/bag-of-tricks-for-image-classification-with-convolutional-neural-networks-in-keras/?fbclid=IwAR2RXBIUkuSdc21cQd3n8AG9CmGtC7MbVgEj3SFm-cfIDyHcexp7YjIhJKs\n","\n","    # Arguments\n","        y: matrix of one-hot row-vector labels to be smoothed\n","        smooth_factor: label smoothing factor (between 0 and 1)\n","\n","    # Returns\n","        A matrix of smoothed labels.\n","    '''\n","    assert len(y.shape) == 2\n","    if 0 <= smooth_factor <= 1:\n","        # label smoothing ref: https://www.robots.ox.ac.uk/~vgg/rg/papers/reinception.pdf\n","        y *= 1 - smooth_factor\n","        y += smooth_factor / y.shape[1]\n","    else:\n","        raise Exception(\n","            'Invalid label smoothing factor: ' + str(smooth_factor))\n","    return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XrM8t7tEm5o6"},"source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    brightness_range = [0.8,1.2],\n","    featurewise_center=False,\n","    featurewise_std_normalization=False,\n","    rotation_range=20,\n","    shear_range=0.1,\n","    zoom_range=0.1,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest')\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dRXdGnz4Rn_t"},"source":["def train_gen(train_datagen) :\n","  while True :\n","    x, y = next(train_datagen)\n","    y = smooth_labels(y, 0.1)\n","    yield x, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3GOMLTOpm8ro","executionInfo":{"status":"ok","timestamp":1607483208517,"user_tz":-420,"elapsed":20879,"user":{"displayName":"Định Mai Thị","photoUrl":"","userId":"04642252131677430012"}},"outputId":"54f57f05-dfbf-4450-96ad-70ad0ddf430b"},"source":["train_generator = train_datagen.flow_from_directory(\n"," train_dir,\n"," color_mode='rgb',\n"," target_size=(197,197),\n"," batch_size=batch_size,\n"," class_mode='categorical',\n"," shuffle=True)\n","\n","validation_generator = validation_datagen.flow_from_directory(\n"," validation_dir,\n"," color_mode='rgb',\n"," target_size=(197,197),\n"," batch_size=batch_size,\n"," class_mode='categorical',\n"," shuffle=True)\n","\n","test_generator = test_datagen.flow_from_directory(\n"," test_dir,\n"," color_mode='rgb',\n"," target_size=(197,197),\n"," batch_size=batch_size,\n"," class_mode='categorical',\n"," shuffle=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 28709 images belonging to 7 classes.\n","Found 3589 images belonging to 7 classes.\n","Found 3589 images belonging to 7 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mkNKYmoqaxBC","executionInfo":{"status":"ok","timestamp":1607746808646,"user_tz":-420,"elapsed":12329,"user":{"displayName":"Huy Tùng Lê","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC-BELBq3FJ4gUF5GAJCad8L5Z1vOHzj8we99ttw=s64","userId":"07175724160568673250"}},"outputId":"284acc82-135f-46c9-c425-290a155e0454"},"source":["!sudo pip install git+https://github.com/rcmalli/keras-vggface.git\n","!pip install Keras-Applications"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/rcmalli/keras-vggface.git\n","  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-45bkqc__\n","  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-45bkqc__\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.18.5)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.10.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (7.0.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.4.3)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.15.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (3.13)\n","Building wheels for collected packages: keras-vggface\n","  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8310 sha256=a5eff90804dd4b2018e3e79d7ccea308c3c324477daa4a93a4fa5384676b8d2f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-5qboupaq/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n","Successfully built keras-vggface\n","Installing collected packages: keras-vggface\n","Successfully installed keras-vggface-0.6\n","Collecting Keras-Applications\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 3.7MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras-Applications) (2.10.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras-Applications) (1.18.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras-Applications) (1.15.0)\n","Installing collected packages: Keras-Applications\n","Successfully installed Keras-Applications-1.0.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RdS5__OmEJWC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607746819157,"user_tz":-420,"elapsed":6688,"user":{"displayName":"Huy Tùng Lê","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC-BELBq3FJ4gUF5GAJCad8L5Z1vOHzj8we99ttw=s64","userId":"07175724160568673250"}},"outputId":"f5291fe6-a053-4518-f945-dd05c38070ad"},"source":["# continue train from check point\n","from keras_vggface.vggface import VGGFace\n","import tensorflow as tf\n","\n","DROPOUT_RATE = 0.5\n","FROZEN_LAYER_NUM = 170\n","\n","vgg_notop = VGGFace(model='resnet50', include_top=False, input_shape=(197, 197, 3), pooling='avg')\n","last_layer = vgg_notop.get_layer('avg_pool').output\n","x = Flatten(name='flatten')(last_layer)\n","x = Dropout(DROPOUT_RATE)(x)\n","x = Dense(4096, activation='relu', name='fc6')(x)\n","x = Dropout(DROPOUT_RATE)(x)\n","x = Dense(1024, activation='relu', name='fc7')(x)\n","x = Dropout(DROPOUT_RATE)(x)\n","\n","batch_norm_indices = [2, 6, 9, 13, 14, 18, 21, 24, 28, 31, 34, 38, 41, 45, 46, 53, 56, 60, 63, 66, 70, 73, 76, 80, 83, 87, 88, 92, 95, 98, 102, 105, 108, 112, 115, 118, 122, 125, 128, 132, 135, 138, 142, 145, 149, 150, 154, 157, 160, 164, 167, 170]\n","for i in range(FROZEN_LAYER_NUM):\n","    if i not in batch_norm_indices:\n","        vgg_notop.layers[i].trainable = False\n","\n","out = Dense(7, activation='softmax', name='classifier')(x)\n","\n","model = tf.keras.Model(vgg_notop.input, out)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n","94699520/94694792 [==============================] - 3s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7YlKsC1RL6go","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1607746978846,"user_tz":-420,"elapsed":882,"user":{"displayName":"Huy Tùng Lê","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC-BELBq3FJ4gUF5GAJCad8L5Z1vOHzj8we99ttw=s64","userId":"07175724160568673250"}},"outputId":"033373de-c57a-4696-eb15-072ff444aa14"},"source":["model.layers[170].name"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'conv5_3_1x1_increase/bn'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1CAuee20La9-","executionInfo":{"status":"ok","timestamp":1607746832556,"user_tz":-420,"elapsed":975,"user":{"displayName":"Huy Tùng Lê","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC-BELBq3FJ4gUF5GAJCad8L5Z1vOHzj8we99ttw=s64","userId":"07175724160568673250"}},"outputId":"dd0653a2-b193-4ca0-b669-387085107dd1"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 197, 197, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv1/7x7_s2 (Conv2D)           (None, 99, 99, 64)   9408        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1/7x7_s2/bn (BatchNormaliza (None, 99, 99, 64)   256         conv1/7x7_s2[0][0]               \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 99, 99, 64)   0           conv1/7x7_s2/bn[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 49, 49, 64)   0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_1_1x1_reduce (Conv2D)     (None, 49, 49, 64)   4096        max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","conv2_1_1x1_reduce/bn (BatchNor (None, 49, 49, 64)   256         conv2_1_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 49, 49, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv2_1_3x3 (Conv2D)            (None, 49, 49, 64)   36864       activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2_1_3x3/bn (BatchNormalizat (None, 49, 49, 64)   256         conv2_1_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 49, 49, 64)   0           conv2_1_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv2_1_1x1_increase (Conv2D)   (None, 49, 49, 256)  16384       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2_1_1x1_proj (Conv2D)       (None, 49, 49, 256)  16384       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","conv2_1_1x1_increase/bn (BatchN (None, 49, 49, 256)  1024        conv2_1_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","conv2_1_1x1_proj/bn (BatchNorma (None, 49, 49, 256)  1024        conv2_1_1x1_proj[0][0]           \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 49, 49, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n","                                                                 conv2_1_1x1_proj/bn[0][0]        \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 49, 49, 256)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2_2_1x1_reduce (Conv2D)     (None, 49, 49, 64)   16384       activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2_2_1x1_reduce/bn (BatchNor (None, 49, 49, 64)   256         conv2_2_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 49, 49, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv2_2_3x3 (Conv2D)            (None, 49, 49, 64)   36864       activation_4[0][0]               \n","__________________________________________________________________________________________________\n","conv2_2_3x3/bn (BatchNormalizat (None, 49, 49, 64)   256         conv2_2_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 49, 49, 64)   0           conv2_2_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv2_2_1x1_increase (Conv2D)   (None, 49, 49, 256)  16384       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2_2_1x1_increase/bn (BatchN (None, 49, 49, 256)  1024        conv2_2_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 49, 49, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n","                                                                 activation_3[0][0]               \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 49, 49, 256)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2_3_1x1_reduce (Conv2D)     (None, 49, 49, 64)   16384       activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2_3_1x1_reduce/bn (BatchNor (None, 49, 49, 64)   256         conv2_3_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 49, 49, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv2_3_3x3 (Conv2D)            (None, 49, 49, 64)   36864       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2_3_3x3/bn (BatchNormalizat (None, 49, 49, 64)   256         conv2_3_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 49, 49, 64)   0           conv2_3_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv2_3_1x1_increase (Conv2D)   (None, 49, 49, 256)  16384       activation_8[0][0]               \n","__________________________________________________________________________________________________\n","conv2_3_1x1_increase/bn (BatchN (None, 49, 49, 256)  1024        conv2_3_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 49, 49, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n","                                                                 activation_6[0][0]               \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 49, 49, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv3_1_1x1_reduce (Conv2D)     (None, 25, 25, 128)  32768       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","conv3_1_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_1_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 25, 25, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv3_1_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv3_1_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_1_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 25, 25, 128)  0           conv3_1_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv3_1_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_11[0][0]              \n","__________________________________________________________________________________________________\n","conv3_1_1x1_proj (Conv2D)       (None, 25, 25, 512)  131072      activation_9[0][0]               \n","__________________________________________________________________________________________________\n","conv3_1_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_1_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","conv3_1_1x1_proj/bn (BatchNorma (None, 25, 25, 512)  2048        conv3_1_1x1_proj[0][0]           \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 25, 25, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n","                                                                 conv3_1_1x1_proj/bn[0][0]        \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 25, 25, 512)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv3_2_1x1_reduce (Conv2D)     (None, 25, 25, 128)  65536       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","conv3_2_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_2_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 25, 25, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv3_2_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_13[0][0]              \n","__________________________________________________________________________________________________\n","conv3_2_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_2_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 25, 25, 128)  0           conv3_2_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv3_2_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","conv3_2_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_2_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 25, 25, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n","                                                                 activation_12[0][0]              \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 25, 25, 512)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","conv3_3_1x1_reduce (Conv2D)     (None, 25, 25, 128)  65536       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","conv3_3_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_3_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 25, 25, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv3_3_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_16[0][0]              \n","__________________________________________________________________________________________________\n","conv3_3_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_3_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 25, 25, 128)  0           conv3_3_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv3_3_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","conv3_3_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_3_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 25, 25, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n","                                                                 activation_15[0][0]              \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 25, 25, 512)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","conv3_4_1x1_reduce (Conv2D)     (None, 25, 25, 128)  65536       activation_18[0][0]              \n","__________________________________________________________________________________________________\n","conv3_4_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_4_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 25, 25, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv3_4_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_19[0][0]              \n","__________________________________________________________________________________________________\n","conv3_4_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_4_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 25, 25, 128)  0           conv3_4_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv3_4_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_20[0][0]              \n","__________________________________________________________________________________________________\n","conv3_4_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_4_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 25, 25, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n","                                                                 activation_18[0][0]              \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 25, 25, 512)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","conv4_1_1x1_reduce (Conv2D)     (None, 13, 13, 256)  131072      activation_21[0][0]              \n","__________________________________________________________________________________________________\n","conv4_1_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_1_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 13, 13, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv4_1_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_22[0][0]              \n","__________________________________________________________________________________________________\n","conv4_1_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_1_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 13, 13, 256)  0           conv4_1_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv4_1_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","conv4_1_1x1_proj (Conv2D)       (None, 13, 13, 1024) 524288      activation_21[0][0]              \n","__________________________________________________________________________________________________\n","conv4_1_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_1_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","conv4_1_1x1_proj/bn (BatchNorma (None, 13, 13, 1024) 4096        conv4_1_1x1_proj[0][0]           \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 13, 13, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n","                                                                 conv4_1_1x1_proj/bn[0][0]        \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 13, 13, 1024) 0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","conv4_2_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_24[0][0]              \n","__________________________________________________________________________________________________\n","conv4_2_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_2_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 13, 13, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv4_2_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","conv4_2_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_2_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 13, 13, 256)  0           conv4_2_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv4_2_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","conv4_2_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_2_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 13, 13, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n","                                                                 activation_24[0][0]              \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 13, 13, 1024) 0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","conv4_3_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_27[0][0]              \n","__________________________________________________________________________________________________\n","conv4_3_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_3_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 13, 13, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv4_3_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","conv4_3_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_3_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 13, 13, 256)  0           conv4_3_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv4_3_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_29[0][0]              \n","__________________________________________________________________________________________________\n","conv4_3_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_3_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 13, 13, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n","                                                                 activation_27[0][0]              \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 13, 13, 1024) 0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","conv4_4_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","conv4_4_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_4_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 13, 13, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv4_4_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","conv4_4_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_4_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 13, 13, 256)  0           conv4_4_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv4_4_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_32[0][0]              \n","__________________________________________________________________________________________________\n","conv4_4_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_4_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 13, 13, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n","                                                                 activation_30[0][0]              \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 13, 13, 1024) 0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","conv4_5_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_33[0][0]              \n","__________________________________________________________________________________________________\n","conv4_5_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_5_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 13, 13, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv4_5_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_34[0][0]              \n","__________________________________________________________________________________________________\n","conv4_5_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_5_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 13, 13, 256)  0           conv4_5_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv4_5_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_35[0][0]              \n","__________________________________________________________________________________________________\n","conv4_5_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_5_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 13, 13, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n","                                                                 activation_33[0][0]              \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 13, 13, 1024) 0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","conv4_6_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","conv4_6_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_6_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 13, 13, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv4_6_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_37[0][0]              \n","__________________________________________________________________________________________________\n","conv4_6_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_6_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 13, 13, 256)  0           conv4_6_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv4_6_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","conv4_6_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_6_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 13, 13, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n","                                                                 activation_36[0][0]              \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 13, 13, 1024) 0           add_12[0][0]                     \n","__________________________________________________________________________________________________\n","conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_39[0][0]              \n","__________________________________________________________________________________________________\n","conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_40[0][0]              \n","__________________________________________________________________________________________________\n","conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_41[0][0]              \n","__________________________________________________________________________________________________\n","conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_39[0][0]              \n","__________________________________________________________________________________________________\n","conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n","__________________________________________________________________________________________________\n","add_13 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n","                                                                 conv5_1_1x1_proj/bn[0][0]        \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n","__________________________________________________________________________________________________\n","conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_42[0][0]              \n","__________________________________________________________________________________________________\n","conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_43[0][0]              \n","__________________________________________________________________________________________________\n","conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_44[0][0]              \n","__________________________________________________________________________________________________\n","conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","add_14 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n","                                                                 activation_42[0][0]              \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n","__________________________________________________________________________________________________\n","conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_45[0][0]              \n","__________________________________________________________________________________________________\n","conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n","__________________________________________________________________________________________________\n","conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_46[0][0]              \n","__________________________________________________________________________________________________\n","conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n","__________________________________________________________________________________________________\n","activation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n","__________________________________________________________________________________________________\n","conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_47[0][0]              \n","__________________________________________________________________________________________________\n","conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n","__________________________________________________________________________________________________\n","add_15 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n","                                                                 activation_45[0][0]              \n","__________________________________________________________________________________________________\n","activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n","__________________________________________________________________________________________________\n","avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_48[0][0]              \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 2048)         0           flatten[0][0]                    \n","__________________________________________________________________________________________________\n","fc6 (Dense)                     (None, 4096)         8392704     dropout[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 4096)         0           fc6[0][0]                        \n","__________________________________________________________________________________________________\n","fc7 (Dense)                     (None, 1024)         4195328     dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 1024)         0           fc7[0][0]                        \n","__________________________________________________________________________________________________\n","classifier (Dense)              (None, 7)            7175        dropout_2[0][0]                  \n","==================================================================================================\n","Total params: 36,156,359\n","Trainable params: 12,648,071\n","Non-trainable params: 23,508,288\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qIH-MhaUnD5k"},"source":["# Compile and Train\n","checkpoint = ModelCheckpoint('/content/drive/MyDrive/fer2013/Resnet50_8_12.h5',\n","                             monitor='val_accuracy',\n","                             mode='max',\n","                             save_best_only=True,\n","                             verbose=1)\n","earlystop = EarlyStopping(monitor='val_loss',\n","                          min_delta=0,\n","                          patience=20,\n","                          verbose=1,\n","                          restore_best_weights=True\n","                          )\n","reduce_lr = ReduceLROnPlateau(monitor='val_accuracy',\n","                              factor=0.5,\n","                              mode = 'max',\n","                              patience=10,\n","                              verbose=1,\n","                              min_lr = 0.00001)\n","callbacks = [earlystop,checkpoint,reduce_lr]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzC3LV8vJtDS"},"source":["optimizer = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-4)\n","sgd = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0001, nesterov=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROFDo-SQnYc6","executionInfo":{"status":"ok","timestamp":1607427128135,"user_tz":-420,"elapsed":5668504,"user":{"displayName":"Định Mai Thị","photoUrl":"","userId":"04642252131677430012"}},"outputId":"c34b8000-cd4f-4c3c-ba83-1d175c6a8c26"},"source":["model.compile(loss='categorical_crossentropy',\n"," optimizer = sgd,\n"," metrics=['accuracy'])\n","\n","nb_train_samples = 28709\n","nb_validation_samples = 3589\n","epochs=100\n","\n","history=model.fit(\n"," train_gen(train_generator),\n"," steps_per_epoch=nb_train_samples//batch_size,\n"," epochs=epochs,\n"," callbacks=callbacks,\n"," validation_data=validation_generator,\n"," validation_steps=nb_validation_samples//batch_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","224/224 [==============================] - ETA: 0s - loss: 1.9420 - accuracy: 0.3155\n","Epoch 00001: val_accuracy improved from -inf to 0.16936, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 345s 2s/step - loss: 1.9420 - accuracy: 0.3155 - val_loss: 1.8953 - val_accuracy: 0.1694\n","Epoch 2/100\n","224/224 [==============================] - ETA: 0s - loss: 1.5733 - accuracy: 0.4400\n","Epoch 00002: val_accuracy improved from 0.16936 to 0.18583, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 339s 2s/step - loss: 1.5733 - accuracy: 0.4400 - val_loss: 1.8918 - val_accuracy: 0.1858\n","Epoch 3/100\n","224/224 [==============================] - ETA: 0s - loss: 1.4870 - accuracy: 0.4891\n","Epoch 00003: val_accuracy improved from 0.18583 to 0.42522, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 338s 2s/step - loss: 1.4870 - accuracy: 0.4891 - val_loss: 1.5148 - val_accuracy: 0.4252\n","Epoch 4/100\n","224/224 [==============================] - ETA: 0s - loss: 1.4424 - accuracy: 0.5124\n","Epoch 00004: val_accuracy improved from 0.42522 to 0.57003, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 337s 2s/step - loss: 1.4424 - accuracy: 0.5124 - val_loss: 1.1857 - val_accuracy: 0.5700\n","Epoch 5/100\n","224/224 [==============================] - ETA: 0s - loss: 1.4019 - accuracy: 0.5390\n","Epoch 00005: val_accuracy improved from 0.57003 to 0.58482, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 335s 1s/step - loss: 1.4019 - accuracy: 0.5390 - val_loss: 1.1605 - val_accuracy: 0.5848\n","Epoch 6/100\n","224/224 [==============================] - ETA: 0s - loss: 1.3817 - accuracy: 0.5467\n","Epoch 00006: val_accuracy improved from 0.58482 to 0.59821, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 334s 1s/step - loss: 1.3817 - accuracy: 0.5467 - val_loss: 1.1407 - val_accuracy: 0.5982\n","Epoch 7/100\n","224/224 [==============================] - ETA: 0s - loss: 1.3559 - accuracy: 0.5613\n","Epoch 00007: val_accuracy improved from 0.59821 to 0.60742, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 333s 1s/step - loss: 1.3559 - accuracy: 0.5613 - val_loss: 1.1244 - val_accuracy: 0.6074\n","Epoch 8/100\n","224/224 [==============================] - ETA: 0s - loss: 1.3347 - accuracy: 0.5680\n","Epoch 00008: val_accuracy improved from 0.60742 to 0.61775, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 334s 1s/step - loss: 1.3347 - accuracy: 0.5680 - val_loss: 1.1156 - val_accuracy: 0.6177\n","Epoch 9/100\n","224/224 [==============================] - ETA: 0s - loss: 1.3199 - accuracy: 0.5773\n","Epoch 00009: val_accuracy improved from 0.61775 to 0.62221, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 335s 1s/step - loss: 1.3199 - accuracy: 0.5773 - val_loss: 1.0986 - val_accuracy: 0.6222\n","Epoch 10/100\n","224/224 [==============================] - ETA: 0s - loss: 1.3020 - accuracy: 0.5870\n","Epoch 00010: val_accuracy improved from 0.62221 to 0.62528, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 334s 1s/step - loss: 1.3020 - accuracy: 0.5870 - val_loss: 1.1078 - val_accuracy: 0.6253\n","Epoch 11/100\n","224/224 [==============================] - ETA: 0s - loss: 1.2945 - accuracy: 0.5907\n","Epoch 00011: val_accuracy improved from 0.62528 to 0.62723, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 333s 1s/step - loss: 1.2945 - accuracy: 0.5907 - val_loss: 1.1006 - val_accuracy: 0.6272\n","Epoch 12/100\n","224/224 [==============================] - ETA: 0s - loss: 1.2801 - accuracy: 0.5960\n","Epoch 00012: val_accuracy did not improve from 0.62723\n","224/224 [==============================] - 331s 1s/step - loss: 1.2801 - accuracy: 0.5960 - val_loss: 1.1183 - val_accuracy: 0.6270\n","Epoch 13/100\n","224/224 [==============================] - ETA: 0s - loss: 1.2715 - accuracy: 0.5997\n","Epoch 00013: val_accuracy improved from 0.62723 to 0.62779, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 333s 1s/step - loss: 1.2715 - accuracy: 0.5997 - val_loss: 1.1045 - val_accuracy: 0.6278\n","Epoch 14/100\n","224/224 [==============================] - ETA: 0s - loss: 1.2624 - accuracy: 0.6060\n","Epoch 00014: val_accuracy improved from 0.62779 to 0.63477, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 334s 1s/step - loss: 1.2624 - accuracy: 0.6060 - val_loss: 1.0917 - val_accuracy: 0.6348\n","Epoch 15/100\n","224/224 [==============================] - ETA: 0s - loss: 1.2572 - accuracy: 0.6092\n","Epoch 00015: val_accuracy improved from 0.63477 to 0.63951, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 335s 1s/step - loss: 1.2572 - accuracy: 0.6092 - val_loss: 1.0990 - val_accuracy: 0.6395\n","Epoch 16/100\n","224/224 [==============================] - ETA: 0s - loss: 1.2434 - accuracy: 0.6150\n","Epoch 00016: val_accuracy did not improve from 0.63951\n","224/224 [==============================] - 332s 1s/step - loss: 1.2434 - accuracy: 0.6150 - val_loss: 1.1083 - val_accuracy: 0.6381\n","Epoch 17/100\n","224/224 [==============================] - ETA: 0s - loss: 1.2362 - accuracy: 0.6187\n","Epoch 00017: val_accuracy improved from 0.63951 to 0.64342, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 334s 1s/step - loss: 1.2362 - accuracy: 0.6187 - val_loss: 1.0953 - val_accuracy: 0.6434\n","Epoch 18/100\n","224/224 [==============================] - ETA: 0s - loss: 1.2332 - accuracy: 0.6195\n","Epoch 00018: val_accuracy did not improve from 0.64342\n","224/224 [==============================] - 332s 1s/step - loss: 1.2332 - accuracy: 0.6195 - val_loss: 1.0940 - val_accuracy: 0.6390\n","Epoch 19/100\n","224/224 [==============================] - ETA: 0s - loss: 1.2240 - accuracy: 0.6245\n","Epoch 00019: val_accuracy improved from 0.64342 to 0.64676, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 334s 1s/step - loss: 1.2240 - accuracy: 0.6245 - val_loss: 1.1102 - val_accuracy: 0.6468\n","Epoch 20/100\n","224/224 [==============================] - ETA: 0s - loss: 1.2114 - accuracy: 0.6320\n","Epoch 00020: val_accuracy improved from 0.64676 to 0.64955, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 334s 1s/step - loss: 1.2114 - accuracy: 0.6320 - val_loss: 1.0851 - val_accuracy: 0.6496\n","Epoch 21/100\n","224/224 [==============================] - ETA: 0s - loss: 1.2079 - accuracy: 0.6312\n","Epoch 00021: val_accuracy did not improve from 0.64955\n","224/224 [==============================] - 332s 1s/step - loss: 1.2079 - accuracy: 0.6312 - val_loss: 1.1097 - val_accuracy: 0.6465\n","Epoch 22/100\n","224/224 [==============================] - ETA: 0s - loss: 1.2045 - accuracy: 0.6358\n","Epoch 00022: val_accuracy improved from 0.64955 to 0.65067, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 334s 1s/step - loss: 1.2045 - accuracy: 0.6358 - val_loss: 1.0932 - val_accuracy: 0.6507\n","Epoch 23/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1990 - accuracy: 0.6358\n","Epoch 00023: val_accuracy improved from 0.65067 to 0.65179, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 335s 1s/step - loss: 1.1990 - accuracy: 0.6358 - val_loss: 1.0839 - val_accuracy: 0.6518\n","Epoch 24/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1890 - accuracy: 0.6413\n","Epoch 00024: val_accuracy improved from 0.65179 to 0.65430, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 334s 1s/step - loss: 1.1890 - accuracy: 0.6413 - val_loss: 1.0655 - val_accuracy: 0.6543\n","Epoch 25/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1873 - accuracy: 0.6440\n","Epoch 00025: val_accuracy improved from 0.65430 to 0.66071, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 335s 1s/step - loss: 1.1873 - accuracy: 0.6440 - val_loss: 1.0707 - val_accuracy: 0.6607\n","Epoch 26/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1824 - accuracy: 0.6436\n","Epoch 00026: val_accuracy did not improve from 0.66071\n","224/224 [==============================] - 332s 1s/step - loss: 1.1824 - accuracy: 0.6436 - val_loss: 1.0758 - val_accuracy: 0.6607\n","Epoch 27/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1754 - accuracy: 0.6467\n","Epoch 00027: val_accuracy did not improve from 0.66071\n","224/224 [==============================] - 332s 1s/step - loss: 1.1754 - accuracy: 0.6467 - val_loss: 1.0776 - val_accuracy: 0.6579\n","Epoch 28/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1714 - accuracy: 0.6503\n","Epoch 00028: val_accuracy did not improve from 0.66071\n","224/224 [==============================] - 332s 1s/step - loss: 1.1714 - accuracy: 0.6503 - val_loss: 1.0683 - val_accuracy: 0.6604\n","Epoch 29/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1678 - accuracy: 0.6511\n","Epoch 00029: val_accuracy did not improve from 0.66071\n","224/224 [==============================] - 332s 1s/step - loss: 1.1678 - accuracy: 0.6511 - val_loss: 1.0987 - val_accuracy: 0.6590\n","Epoch 30/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1635 - accuracy: 0.6530\n","Epoch 00030: val_accuracy improved from 0.66071 to 0.66518, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 335s 1s/step - loss: 1.1635 - accuracy: 0.6530 - val_loss: 1.0825 - val_accuracy: 0.6652\n","Epoch 31/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1551 - accuracy: 0.6569\n","Epoch 00031: val_accuracy did not improve from 0.66518\n","224/224 [==============================] - 332s 1s/step - loss: 1.1551 - accuracy: 0.6569 - val_loss: 1.0765 - val_accuracy: 0.6616\n","Epoch 32/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1521 - accuracy: 0.6608\n","Epoch 00032: val_accuracy did not improve from 0.66518\n","224/224 [==============================] - 332s 1s/step - loss: 1.1521 - accuracy: 0.6608 - val_loss: 1.0797 - val_accuracy: 0.6613\n","Epoch 33/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1503 - accuracy: 0.6603\n","Epoch 00033: val_accuracy improved from 0.66518 to 0.66574, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 334s 1s/step - loss: 1.1503 - accuracy: 0.6603 - val_loss: 1.0792 - val_accuracy: 0.6657\n","Epoch 34/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1453 - accuracy: 0.6627\n","Epoch 00034: val_accuracy improved from 0.66574 to 0.66825, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 335s 1s/step - loss: 1.1453 - accuracy: 0.6627 - val_loss: 1.0735 - val_accuracy: 0.6682\n","Epoch 35/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1376 - accuracy: 0.6658\n","Epoch 00035: val_accuracy did not improve from 0.66825\n","224/224 [==============================] - 332s 1s/step - loss: 1.1376 - accuracy: 0.6658 - val_loss: 1.0602 - val_accuracy: 0.6652\n","Epoch 36/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1358 - accuracy: 0.6692\n","Epoch 00036: val_accuracy improved from 0.66825 to 0.67160, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 335s 1s/step - loss: 1.1358 - accuracy: 0.6692 - val_loss: 1.0624 - val_accuracy: 0.6716\n","Epoch 37/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1390 - accuracy: 0.6711\n","Epoch 00037: val_accuracy improved from 0.67160 to 0.67355, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 335s 1s/step - loss: 1.1390 - accuracy: 0.6711 - val_loss: 1.0656 - val_accuracy: 0.6735\n","Epoch 38/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1300 - accuracy: 0.6701\n","Epoch 00038: val_accuracy did not improve from 0.67355\n","224/224 [==============================] - 332s 1s/step - loss: 1.1300 - accuracy: 0.6701 - val_loss: 1.0643 - val_accuracy: 0.6719\n","Epoch 39/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1278 - accuracy: 0.6742\n","Epoch 00039: val_accuracy improved from 0.67355 to 0.67494, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 335s 1s/step - loss: 1.1278 - accuracy: 0.6742 - val_loss: 1.0694 - val_accuracy: 0.6749\n","Epoch 40/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1168 - accuracy: 0.6786\n","Epoch 00040: val_accuracy did not improve from 0.67494\n","224/224 [==============================] - 333s 1s/step - loss: 1.1168 - accuracy: 0.6786 - val_loss: 1.0632 - val_accuracy: 0.6727\n","Epoch 41/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1231 - accuracy: 0.6721\n","Epoch 00041: val_accuracy improved from 0.67494 to 0.67578, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 334s 1s/step - loss: 1.1231 - accuracy: 0.6721 - val_loss: 1.0799 - val_accuracy: 0.6758\n","Epoch 42/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1155 - accuracy: 0.6812\n","Epoch 00042: val_accuracy improved from 0.67578 to 0.67969, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 335s 1s/step - loss: 1.1155 - accuracy: 0.6812 - val_loss: 1.0620 - val_accuracy: 0.6797\n","Epoch 43/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1130 - accuracy: 0.6788\n","Epoch 00043: val_accuracy did not improve from 0.67969\n","224/224 [==============================] - 333s 1s/step - loss: 1.1130 - accuracy: 0.6788 - val_loss: 1.0590 - val_accuracy: 0.6777\n","Epoch 44/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1054 - accuracy: 0.6851\n","Epoch 00044: val_accuracy did not improve from 0.67969\n","224/224 [==============================] - 334s 1s/step - loss: 1.1054 - accuracy: 0.6851 - val_loss: 1.0607 - val_accuracy: 0.6775\n","Epoch 45/100\n","224/224 [==============================] - ETA: 0s - loss: 1.1015 - accuracy: 0.6838\n","Epoch 00045: val_accuracy improved from 0.67969 to 0.68583, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 344s 2s/step - loss: 1.1015 - accuracy: 0.6838 - val_loss: 1.0538 - val_accuracy: 0.6858\n","Epoch 46/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0949 - accuracy: 0.6898\n","Epoch 00046: val_accuracy did not improve from 0.68583\n","224/224 [==============================] - 349s 2s/step - loss: 1.0949 - accuracy: 0.6898 - val_loss: 1.0564 - val_accuracy: 0.6800\n","Epoch 47/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0953 - accuracy: 0.6873\n","Epoch 00047: val_accuracy did not improve from 0.68583\n","224/224 [==============================] - 346s 2s/step - loss: 1.0953 - accuracy: 0.6873 - val_loss: 1.0473 - val_accuracy: 0.6780\n","Epoch 48/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0960 - accuracy: 0.6876\n","Epoch 00048: val_accuracy did not improve from 0.68583\n","224/224 [==============================] - 337s 2s/step - loss: 1.0960 - accuracy: 0.6876 - val_loss: 1.0655 - val_accuracy: 0.6822\n","Epoch 49/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0924 - accuracy: 0.6918\n","Epoch 00049: val_accuracy did not improve from 0.68583\n","224/224 [==============================] - 335s 1s/step - loss: 1.0924 - accuracy: 0.6918 - val_loss: 1.0558 - val_accuracy: 0.6805\n","Epoch 50/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0899 - accuracy: 0.6894\n","Epoch 00050: val_accuracy did not improve from 0.68583\n","224/224 [==============================] - 334s 1s/step - loss: 1.0899 - accuracy: 0.6894 - val_loss: 1.0583 - val_accuracy: 0.6822\n","Epoch 51/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0817 - accuracy: 0.6963\n","Epoch 00051: val_accuracy did not improve from 0.68583\n","224/224 [==============================] - 338s 2s/step - loss: 1.0817 - accuracy: 0.6963 - val_loss: 1.0680 - val_accuracy: 0.6808\n","Epoch 52/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0822 - accuracy: 0.6985\n","Epoch 00052: val_accuracy did not improve from 0.68583\n","224/224 [==============================] - 339s 2s/step - loss: 1.0822 - accuracy: 0.6985 - val_loss: 1.0544 - val_accuracy: 0.6825\n","Epoch 53/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0793 - accuracy: 0.6953\n","Epoch 00053: val_accuracy did not improve from 0.68583\n","224/224 [==============================] - 339s 2s/step - loss: 1.0793 - accuracy: 0.6953 - val_loss: 1.0610 - val_accuracy: 0.6844\n","Epoch 54/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0743 - accuracy: 0.7006\n","Epoch 00054: val_accuracy improved from 0.68583 to 0.68666, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 342s 2s/step - loss: 1.0743 - accuracy: 0.7006 - val_loss: 1.0661 - val_accuracy: 0.6867\n","Epoch 55/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0707 - accuracy: 0.7017\n","Epoch 00055: val_accuracy did not improve from 0.68666\n","224/224 [==============================] - 343s 2s/step - loss: 1.0707 - accuracy: 0.7017 - val_loss: 1.0495 - val_accuracy: 0.6822\n","Epoch 56/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0717 - accuracy: 0.7030\n","Epoch 00056: val_accuracy did not improve from 0.68666\n","224/224 [==============================] - 335s 1s/step - loss: 1.0717 - accuracy: 0.7030 - val_loss: 1.0547 - val_accuracy: 0.6858\n","Epoch 57/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0656 - accuracy: 0.7027\n","Epoch 00057: val_accuracy did not improve from 0.68666\n","224/224 [==============================] - 336s 1s/step - loss: 1.0656 - accuracy: 0.7027 - val_loss: 1.0566 - val_accuracy: 0.6811\n","Epoch 58/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0632 - accuracy: 0.7075\n","Epoch 00058: val_accuracy improved from 0.68666 to 0.68778, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 345s 2s/step - loss: 1.0632 - accuracy: 0.7075 - val_loss: 1.0456 - val_accuracy: 0.6878\n","Epoch 59/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0638 - accuracy: 0.7061\n","Epoch 00059: val_accuracy improved from 0.68778 to 0.68862, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 337s 2s/step - loss: 1.0638 - accuracy: 0.7061 - val_loss: 1.0586 - val_accuracy: 0.6886\n","Epoch 60/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0550 - accuracy: 0.7066\n","Epoch 00060: val_accuracy did not improve from 0.68862\n","224/224 [==============================] - 337s 2s/step - loss: 1.0550 - accuracy: 0.7066 - val_loss: 1.0375 - val_accuracy: 0.6878\n","Epoch 61/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0540 - accuracy: 0.7111\n","Epoch 00061: val_accuracy improved from 0.68862 to 0.68890, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 341s 2s/step - loss: 1.0540 - accuracy: 0.7111 - val_loss: 1.0394 - val_accuracy: 0.6889\n","Epoch 62/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0523 - accuracy: 0.7096\n","Epoch 00062: val_accuracy did not improve from 0.68890\n","224/224 [==============================] - 339s 2s/step - loss: 1.0523 - accuracy: 0.7096 - val_loss: 1.0505 - val_accuracy: 0.6864\n","Epoch 63/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0454 - accuracy: 0.7157\n","Epoch 00063: val_accuracy did not improve from 0.68890\n","224/224 [==============================] - 339s 2s/step - loss: 1.0454 - accuracy: 0.7157 - val_loss: 1.0446 - val_accuracy: 0.6822\n","Epoch 64/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0427 - accuracy: 0.7150\n","Epoch 00064: val_accuracy did not improve from 0.68890\n","224/224 [==============================] - 339s 2s/step - loss: 1.0427 - accuracy: 0.7150 - val_loss: 1.0459 - val_accuracy: 0.6858\n","Epoch 65/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0509 - accuracy: 0.7131\n","Epoch 00065: val_accuracy improved from 0.68890 to 0.68917, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 343s 2s/step - loss: 1.0509 - accuracy: 0.7131 - val_loss: 1.0430 - val_accuracy: 0.6892\n","Epoch 66/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0409 - accuracy: 0.7168\n","Epoch 00066: val_accuracy did not improve from 0.68917\n","224/224 [==============================] - 342s 2s/step - loss: 1.0409 - accuracy: 0.7168 - val_loss: 1.0463 - val_accuracy: 0.6853\n","Epoch 67/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0408 - accuracy: 0.7185\n","Epoch 00067: val_accuracy did not improve from 0.68917\n","224/224 [==============================] - 348s 2s/step - loss: 1.0408 - accuracy: 0.7185 - val_loss: 1.0483 - val_accuracy: 0.6861\n","Epoch 68/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0390 - accuracy: 0.7185\n","Epoch 00068: val_accuracy did not improve from 0.68917\n","224/224 [==============================] - 351s 2s/step - loss: 1.0390 - accuracy: 0.7185 - val_loss: 1.0400 - val_accuracy: 0.6864\n","Epoch 69/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0321 - accuracy: 0.7211\n","Epoch 00069: val_accuracy did not improve from 0.68917\n","224/224 [==============================] - 357s 2s/step - loss: 1.0321 - accuracy: 0.7211 - val_loss: 1.0370 - val_accuracy: 0.6872\n","Epoch 70/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0368 - accuracy: 0.7204\n","Epoch 00070: val_accuracy did not improve from 0.68917\n","224/224 [==============================] - 353s 2s/step - loss: 1.0368 - accuracy: 0.7204 - val_loss: 1.0368 - val_accuracy: 0.6886\n","Epoch 71/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0320 - accuracy: 0.7214\n","Epoch 00071: val_accuracy improved from 0.68917 to 0.69057, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 356s 2s/step - loss: 1.0320 - accuracy: 0.7214 - val_loss: 1.0339 - val_accuracy: 0.6906\n","Epoch 72/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0290 - accuracy: 0.7239\n","Epoch 00072: val_accuracy did not improve from 0.69057\n","224/224 [==============================] - 352s 2s/step - loss: 1.0290 - accuracy: 0.7239 - val_loss: 1.0409 - val_accuracy: 0.6869\n","Epoch 73/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0254 - accuracy: 0.7252\n","Epoch 00073: val_accuracy did not improve from 0.69057\n","224/224 [==============================] - 356s 2s/step - loss: 1.0254 - accuracy: 0.7252 - val_loss: 1.0364 - val_accuracy: 0.6867\n","Epoch 74/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0286 - accuracy: 0.7233\n","Epoch 00074: val_accuracy did not improve from 0.69057\n","224/224 [==============================] - 346s 2s/step - loss: 1.0286 - accuracy: 0.7233 - val_loss: 1.0347 - val_accuracy: 0.6895\n","Epoch 75/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0219 - accuracy: 0.7290\n","Epoch 00075: val_accuracy improved from 0.69057 to 0.69587, saving model to /content/drive/MyDrive/fer2013/Resnet50_8_12.h5\n","224/224 [==============================] - 344s 2s/step - loss: 1.0219 - accuracy: 0.7290 - val_loss: 1.0323 - val_accuracy: 0.6959\n","Epoch 76/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0168 - accuracy: 0.7295\n","Epoch 00076: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 344s 2s/step - loss: 1.0168 - accuracy: 0.7295 - val_loss: 1.0342 - val_accuracy: 0.6897\n","Epoch 77/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0106 - accuracy: 0.7359\n","Epoch 00077: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 355s 2s/step - loss: 1.0106 - accuracy: 0.7359 - val_loss: 1.0287 - val_accuracy: 0.6928\n","Epoch 78/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0137 - accuracy: 0.7347\n","Epoch 00078: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 364s 2s/step - loss: 1.0137 - accuracy: 0.7347 - val_loss: 1.0259 - val_accuracy: 0.6948\n","Epoch 79/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0081 - accuracy: 0.7366\n","Epoch 00079: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 361s 2s/step - loss: 1.0081 - accuracy: 0.7366 - val_loss: 1.0139 - val_accuracy: 0.6956\n","Epoch 80/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0120 - accuracy: 0.7315\n","Epoch 00080: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 364s 2s/step - loss: 1.0120 - accuracy: 0.7315 - val_loss: 1.0292 - val_accuracy: 0.6936\n","Epoch 81/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0070 - accuracy: 0.7369\n","Epoch 00081: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 364s 2s/step - loss: 1.0070 - accuracy: 0.7369 - val_loss: 1.0172 - val_accuracy: 0.6867\n","Epoch 82/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0053 - accuracy: 0.7390\n","Epoch 00082: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 365s 2s/step - loss: 1.0053 - accuracy: 0.7390 - val_loss: 1.0268 - val_accuracy: 0.6883\n","Epoch 83/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9970 - accuracy: 0.7418\n","Epoch 00083: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 365s 2s/step - loss: 0.9970 - accuracy: 0.7418 - val_loss: 1.0237 - val_accuracy: 0.6928\n","Epoch 84/100\n","224/224 [==============================] - ETA: 0s - loss: 1.0036 - accuracy: 0.7387\n","Epoch 00084: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 369s 2s/step - loss: 1.0036 - accuracy: 0.7387 - val_loss: 1.0204 - val_accuracy: 0.6911\n","Epoch 85/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9989 - accuracy: 0.7411\n","Epoch 00085: val_accuracy did not improve from 0.69587\n","\n","Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n","224/224 [==============================] - 367s 2s/step - loss: 0.9989 - accuracy: 0.7411 - val_loss: 1.0251 - val_accuracy: 0.6903\n","Epoch 86/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9891 - accuracy: 0.7460\n","Epoch 00086: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 367s 2s/step - loss: 0.9891 - accuracy: 0.7460 - val_loss: 1.0234 - val_accuracy: 0.6925\n","Epoch 87/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9911 - accuracy: 0.7456\n","Epoch 00087: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 367s 2s/step - loss: 0.9911 - accuracy: 0.7456 - val_loss: 1.0179 - val_accuracy: 0.6900\n","Epoch 88/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9862 - accuracy: 0.7471\n","Epoch 00088: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 366s 2s/step - loss: 0.9862 - accuracy: 0.7471 - val_loss: 1.0199 - val_accuracy: 0.6911\n","Epoch 89/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9833 - accuracy: 0.7472\n","Epoch 00089: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 368s 2s/step - loss: 0.9833 - accuracy: 0.7472 - val_loss: 1.0204 - val_accuracy: 0.6920\n","Epoch 90/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9864 - accuracy: 0.7482\n","Epoch 00090: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 368s 2s/step - loss: 0.9864 - accuracy: 0.7482 - val_loss: 1.0235 - val_accuracy: 0.6911\n","Epoch 91/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9819 - accuracy: 0.7500\n","Epoch 00091: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 367s 2s/step - loss: 0.9819 - accuracy: 0.7500 - val_loss: 1.0197 - val_accuracy: 0.6914\n","Epoch 92/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9789 - accuracy: 0.7509\n","Epoch 00092: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 366s 2s/step - loss: 0.9789 - accuracy: 0.7509 - val_loss: 1.0153 - val_accuracy: 0.6928\n","Epoch 93/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9810 - accuracy: 0.7482\n","Epoch 00093: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 358s 2s/step - loss: 0.9810 - accuracy: 0.7482 - val_loss: 1.0219 - val_accuracy: 0.6931\n","Epoch 94/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9763 - accuracy: 0.7549\n","Epoch 00094: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 337s 2s/step - loss: 0.9763 - accuracy: 0.7549 - val_loss: 1.0214 - val_accuracy: 0.6911\n","Epoch 95/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9839 - accuracy: 0.7465\n","Epoch 00095: val_accuracy did not improve from 0.69587\n","\n","Epoch 00095: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n","224/224 [==============================] - 334s 1s/step - loss: 0.9839 - accuracy: 0.7465 - val_loss: 1.0178 - val_accuracy: 0.6928\n","Epoch 96/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9819 - accuracy: 0.7483\n","Epoch 00096: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 333s 1s/step - loss: 0.9819 - accuracy: 0.7483 - val_loss: 1.0197 - val_accuracy: 0.6931\n","Epoch 97/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9763 - accuracy: 0.7554\n","Epoch 00097: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 334s 1s/step - loss: 0.9763 - accuracy: 0.7554 - val_loss: 1.0200 - val_accuracy: 0.6953\n","Epoch 98/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9783 - accuracy: 0.7512\n","Epoch 00098: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 333s 1s/step - loss: 0.9783 - accuracy: 0.7512 - val_loss: 1.0201 - val_accuracy: 0.6945\n","Epoch 99/100\n","224/224 [==============================] - ETA: 0s - loss: 0.9751 - accuracy: 0.7526Restoring model weights from the end of the best epoch.\n","\n","Epoch 00099: val_accuracy did not improve from 0.69587\n","224/224 [==============================] - 333s 1s/step - loss: 0.9751 - accuracy: 0.7526 - val_loss: 1.0190 - val_accuracy: 0.6945\n","Epoch 00099: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":590},"id":"HmbrHzQUnavr","executionInfo":{"status":"ok","timestamp":1607427128138,"user_tz":-420,"elapsed":57,"user":{"displayName":"Định Mai Thị","photoUrl":"","userId":"04642252131677430012"}},"outputId":"aa54f365-9641-4261-dd20-6f9a801ccc75"},"source":["print(history.history.keys())\n","\n","# summarize history for accuracy\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"joe9gik50vVa"},"source":["import tensorflow as tf\n","model = tf.keras.models.load_model(\"/content/drive/MyDrive/huytung/Resnet50_8_12.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bQczfHnffKGF"},"source":["import tensorflow as tf\n","model = tf.keras.models.load_model(\"/content/drive/MyDrive/huytung/VGGFace16.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438},"id":"LxOp7J9S1BXz","executionInfo":{"status":"error","timestamp":1607483596979,"user_tz":-420,"elapsed":5616,"user":{"displayName":"Định Mai Thị","photoUrl":"","userId":"04642252131677430012"}},"outputId":"f904522b-1c8e-46e9-f293-f94a6668bbf6"},"source":["print('\\n# Evaluate on test data')\n","results_test = model.evaluate_generator(test_generator, 3589 // batch_size)\n","print('test loss, test acc:', results_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","# Evaluate on test data\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-9c1252e0d517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n# Evaluate on test data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3589\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test loss, test acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1855\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1857\u001b[0;31m         callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m   @deprecation.deprecated(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m:  Input to reshape is a tensor with 2359296 values, but the requested shape requires a multiple of 25088\n\t [[node functional_3/flatten/Reshape (defined at <ipython-input-19-9c1252e0d517>:2) ]] [Op:__inference_test_function_15892]\n\nFunction call stack:\ntest_function\n"]}]},{"cell_type":"code","metadata":{"id":"uh0hRDKX1LFz"},"source":["print('\\n# Evaluate on test data')\n","results_test = model.evaluate_generator(validation_generator, 3589 // batch_size)\n","print('test loss, test acc:', results_test)"],"execution_count":null,"outputs":[]}]}